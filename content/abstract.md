## Abstract

We present **[MappingChange](https://github.com/francesNLP/MappingChange)**, a project that constructs a temporal and semantic knowledge base from ten 19th-century **[Gazetteers of Scotland](https://data.nls.uk/data/digitised-collections/gazetteers-of-scotland/)** (1803â€“1901), digitized as over 13,000 page-level **XML** files. These noisy, unstructured texts lack article-level markup and exhibit highly heterogeneous layouts. To segment and structure over 50,000 historical place descriptions, we employ **large language models (LLMs)** with **edition-specific prompting strategies**, tuned to handle distinct editorial conventions, abbreviations, place-name disambiguation, and multi-page entries. The resulting knowledge base comprises three interlinked knowledge graphs: (1) a **basic KG**, extracted from cleaned DataFrames; (2) a **concept-enriched KG**, linking semantically similar place records across editions using **sentence embeddings**, **Wikidata**, and **DBpedia**; and (3) a **location-annotated KG**, enriched with **named entity recognition**. All are expressed in **[RDF](https://www.w3.org/RDF/)** and modeled with the updated **[Heritage Textual Ontology (HTO)](https://w3id.org/hto)**, which provides a structured vocabulary for capturing textual provenance, bibliographic metadata, extraction context, and diachronic semantic alignment across editions. In addition to the knowledge graphs, we release: (a) individual DataFrames for each edition, (b) a unified cross-edition DataFrame, and (c) Jupyter Notebooks to use our resources. All resources are integrated into the [Frances](http://www.frances-ai.com) semantic web platform, enabling historical exploration through keyword and semantic search, as well as through interactive visualizations.

