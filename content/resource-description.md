## Resource Description
{:#resourcedescription}

The MappingChange resource provides a reusable, modular knowledge base that transforms the digitized [Gazetteers of Scotland](https://data.nls.uk/data/metadata-collections/gazetteers-of-scotland/) (1803–1901) into a structured and semantically enriched dataset for historical place-based analysis. Central to the resource are volume-specific JSON DataFrames containing over 50,000 articles—each corresponding to a place entry—extracted from OCR-aligned ALTO XML using edition-specific GPT-4 prompts. These DataFrames include article text, identified place names, and structured metadata such as edition, volume, page number, and word count. Each DataFrame is normalized to a one-entry-per-row format, making it suitable for downstream integration and statistical analysis. We provide both individual DataFrames for each of the ten editions and a unified, cross-edition DataFrame that aggregates all entries into a single structure. 

These DataFrames serve as the foundation for constructing three interlinked RDF knowledge graphs, modeled using the [Heritage Textual Ontology (HTO)](https://w3id.org/hto), which captures both textual provenance and semantic transformations. The first knowledge graph encodes cleaned article-level records and their bibliographic context, preserving references to their original digitized pages. The second graph includes pre-computed sentence embeddings for each article and introduces concept-level alignment by clustering semantically equivalent entries across editions, assigning persistent identifiers and linking them to external entities such as [Wikidata](https://www.wikidata.org) and [DBpedia](https://www.dbpedia.org). The third graph adds geographic enrichment, using named entity recognition and georesolution techniques to annotate articles with location coordinates and spatial types. Together, these layers enable advanced temporal and semantic analysis of how places were described over time in the Scottish Gazetteers.

All knowledge graphs are serialized in RDF/Turtle and adhere to FAIR data principles. Outputs are hosted in a public [Fuseki SPARQL endpoint](http://query.frances-ai.com/hto_gazetteers), and are complemented by a curated set of Jupyter notebooks. These include SPARQL query examples and data exploration analyses. The three interlinked knowledge graphs are deployed within the [Frances](http://www.frances-ai.com) semantic platform, providing users with interactive interfaces for querying, timeline visualization, and concept exploration. 

The full resource (including individual and aggregated DataFrames, knowledge graphs, and exploratory notebooks) is openly available at [MappingChange repository](https://github.com/francesNLP/MappingChange), with persistent identifiers to be issued via Zenodo. To promote reuse and reproducibility, the repository includes modular scripts and comprehensive documentation. The step-by-step process by which the data and knowledge graphs are constructed—including article extraction, enrichment, and RDF serialization—is described in [Section 5](#resourceconstruction).


