<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <meta charset="utf-8" />
  <title property="foaf:name schema:name">Mapping Change: A Temporal and Semantic Knowledge Base of Scottish Gazetteers (1803–1901)</title>
  <link rel="stylesheet" media="screen" href="styles/screen.css" />
  <link rel="stylesheet" media="print" href="styles/strict-print.css" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  
  <meta name="citation_title" content="Mapping Change: A Temporal and Semantic Knowledge Base of Scottish Gazetteers (1803–1901)">
  
  
  <meta name="citation_publication_date" content="2025/05/08" />
</head>

<body prefix="dctypes: http://purl.org/dc/dcmitype/ pimspace: http://www.w3.org/ns/pim/space# rsa: http://www.w3.org/ns/auth/rsa# cert: http://www.w3.org/ns/auth/cert# wgs: http://www.w3.org/2003/01/geo/wgs84_pos# biblio: http://purl.org/net/biblio# bibo: http://purl.org/ontology/bibo/ book: http://purl.org/NET/book/vocab# ov: http://open.vocab.org/terms/ doap: http://usefulinc.com/ns/doap# dbr: http://dbpedia.org/resource/ dbp: http://dbpedia.org/property/ sio: http://semanticscience.org/resource/ opmw: http://www.opmw.org/ontology/ deo: http://purl.org/spar/deo/ doco: http://purl.org/spar/doco/ cito: http://purl.org/spar/cito/ fabio: http://purl.org/spar/fabio/ solid: http://www.w3.org/ns/solid/terms# acl: http://www.w3.org/ns/auth/acl# dio: https://w3id.org/dio# lsc: http://linkedscience.org/lsc/ns#" typeof="schema:CreativeWork sioc:Post prov:Entity lsc:Research">
  <header>
  <h1>Mapping Change: A Temporal and Semantic Knowledge Base of Scottish Gazetteers (1803–1901)</h1>
  <p>
    <strong>Lilin Yu</strong>, <strong>Rosa Filgueira</strong><br />
    EPCC, University of Edinburgh<br />
    <a href="mailto:L.Yu-40@sms.ed.ac.uk">L.Yu-40@sms.ed.ac.uk</a>,
    <a href="mailto:r.filgueira@epcc.ed.ac.uk">r.filgueira@epcc.ed.ac.uk</a>
  </p>
  <p><strong>Identifier:</strong> <a href="https://rosafilgueira.github.io/MappingChange-Paper-ISWC2025/">https:/​/​rosafilgueira.github.io/MappingChange-Paper-ISWC2025/</a></p>
</header>

<!-- Hack to make our custom fonts load in print-mode -->
<p><span class="printfont1"> </span>
<span class="printfont2"> </span>
<span class="printfont3"> </span>
<span class="printfont4"> </span></p>

<div id="content">
  <section id="abstract" inlist="" rel="schema:hasPart" resource="#abstract">
<div datatype="rdf:HTML" property="schema:description">
      <h2 property="schema:name">Abstract</h2>

      <p>We present <strong><a href="https://github.com/francesNLP/MappingChange">MappingChange</a></strong>, a project that constructs a temporal and semantic knowledge base from ten 19th-century <strong><a href="https://data.nls.uk/data/digitised-collections/gazetteers-of-scotland/">Gazetteers of Scotland</a></strong> (1803–1901), digitized as over 13,000 page-level <strong>XML</strong> files. These noisy, unstructured texts lack article-level markup and exhibit highly heterogeneous layouts. To segment and structure over 50,000 historical place descriptions, we employ <strong>large language models (LLMs)</strong> with <strong>edition-specific prompting strategies</strong>, tuned to handle distinct editorial conventions, abbreviations, place-name disambiguation, and multi-page entries. The resulting knowledge base comprises three interlinked knowledge graphs: (1) a <strong>basic KG</strong>, extracted from cleaned DataFrames; (2) a <strong>concept-enriched KG</strong>, linking semantically similar place records across editions using <strong>sentence embeddings</strong>, <strong>Wikidata</strong>, and <strong>DBpedia</strong>; and (3) a <strong>location-annotated KG</strong>, enriched with <strong>named entity recognition</strong>. All are expressed in <strong><a href="https://www.w3.org/RDF/">RDF</a></strong> and modeled with the updated <strong><a href="https://w3id.org/hto">Heritage Textual Ontology (HTO)</a></strong>, which provides a structured vocabulary for capturing textual provenance, bibliographic metadata, extraction context, and diachronic semantic alignment across editions. In addition to the knowledge graphs, we release: (a) individual DataFrames for each edition, (b) a unified cross-edition DataFrame, and (c) Elasticsearch indices. All resources are integrated into the <a href="http://www.frances-ai.com">Frances</a> semantic web platform, enabling historical exploration through keyword and semantic search, as well as through interactive visualizations.</p>

    </div>
</section>


<main>
  <section id="introduction" inlist="" rel="schema:hasPart" resource="#introduction">
<div datatype="rdf:HTML" property="schema:description">
        <h2 property="schema:name">Introduction</h2>

        <p>Descriptive gazetteers were a cornerstone of how 19th-century Scotland recorded and transmitted its geographical knowledge—capturing towns, parishes, rivers, castles, and natural features within evolving historical, social, and economic narratives. As industrialization, migration, land reform, and empire reshaped the country, these texts became critical instruments for documenting change. The <em>Gazetteers of Scotland, 1803–1901</em>, digitized by the <a href="https://data.nls.uk/data/digitised-collections">National Library of Scotland (NLS)</a>, form one of the most extensive corpora for studying this spatial transformation. Yet despite being released as more than 13,000 OCR-aligned ALTO XML files, the collection remains largely unsuitable for structured analysis. The lack of article-level markup, noisy layouts, and inconsistent editorial conventions limit its accessibility for digital scholarship.</p>

        <p>Each edition introduces distinct typographic conventions for article headers, redirects, abbreviations, and multi-page entries. In early volumes, place names appear in uppercase with minimal punctuation to separate entries (Figure 1, left), whereas later editions use clearer formatting, including title casing and consistent delimiters (Figure 1, right). These variations complicate traditional rule-based approaches to text segmentation and alignment, making it difficult to trace how a place is described across time or to resolve recurring names that refer to different locations.</p>

        <p>Compounding these challenges is the fact that many place names (e.g. “ABBEY”) recur across the gazetteers, often referring to different locations. Moreover, later editions tend to include a broader set of places, meaning some names appear for the first time in later volumes or gain more detailed descriptions over time. Disambiguating such entries is non-trivial, as it depends on contextual clues within each article rather than surface-level patterns. Our approach relies on LLM-based article segmentation and interpretation—capturing subtle editorial cues and semantic context to associate each name with the appropriate description.</p>

        <p>To overcome these limitations, we present <strong>MappingChange</strong>, a reusable and openly licensed resource that transforms this historically rich but structurally fragmented corpus into a structured and semantically enriched knowledge base. Our pipeline uses large language models (LLMs) with edition-specific prompt strategies to extract over 50,000 article-level entries and express them in RDF as three interlinked knowledge graphs, modeled using the <a href="https://w3id.org/hto">Heritage Textual Ontology (HTO)</a>. The resulting knowledge base supports both <strong>temporal analysis</strong>, enabling comparison of how place descriptions change across editions, and <strong>semantic exploration</strong>, through the linking of conceptually related entries and connections to <a href="https://www.wikidata.org">Wikidata</a> and <a href="https://www.dbpedia.org">DBpedia</a>.</p>

        <p>A full account of the dataset structure, file formats, and access methods is provided in <a href="#resourcedescription">Section 3</a>. All components—including JSON DataFrames, RDF knowledge graphs, and Elasticsearch indices—are made available via <a href="https://github.com/francesNLP/MappingChange">github.com/francesNLP/MappingChange</a> and integrated into the <a href="http://www.frances-ai.com">Frances</a> semantic platform, supporting FAIR access, reproducibility, and visual exploration.</p>

        <div style="display: flex; justify-content: space-between; align-items: flex-start; gap: 1em;">
  <div style="flex: 1; text-align: center;">
    <img src="images/1803-gazetteer-page.jpg" alt="First page of the 1803 Gazetteer of Scotland" style="max-width: 180px; height: auto; border: 1px solid #ccc;" />
    <p style="font-size: 0.9em;">
      <strong>Figure 1 (left):</strong> Opening entries of the 1803 <em>Gazetteer of Scotland</em>. Page headers consist of two three-letter uppercase segments (e.g., “ABB ABE”). Place names appear in all caps, typically followed by a period or semicolon—offering minimal typographic separation between entries.
    </p>
  </div>
  <div style="flex: 1; text-align: center;">
    <img src="images/1884-gazetteer-page.jpg" alt="First page of the 1884 Ordnance Gazetteer of Scotland" style="max-width: 200px; height: auto; border: 1px solid #ccc;" />
    <p style="font-size: 0.9em;">
        <strong>Figure 1 (right):</strong> Opening entries of the 1884 <em>Ordnance Gazetteer of Scotland</em>. This edition features a clearer visual structure, with entries formatted in title case and followed by commas. Page headers display the first and last place names on the page, both rendered in uppercase.
    </p>
  </div>
</div>

        <p>All components—DataFrames, RDF knowledge graphs, and Elasticsearch indices—are reproducible from source using openly available scripts, which are detailed in <a href="#resourceconstruction">Section 5</a>. This enables other researchers to reuse, adapt, or extend the MappingChange infrastructure for new corpora, ensuring FAIR data practices and long-term sustainability. In doing so, the project facilitates new forms of historical geography and cultural analytics by making a corpus computationally interoperable, queryable, and reusable across domains.</p>

        <p>The remainder of this paper is structured as follows. <a href="#relatedwork">Section 2</a> reviews related work on Semantic Web methods for cultural heritage, including digitization, ontology design, and the use of large language model. <a href="#resourcedescription">Section 3</a> provides a detailed description of the MappingChange resource. <a href="#hto">Section 4</a> details the Heritage Textual Ontology. <a href="#resourceconstruction">Section 5</a> outlines the end-to-end pipeline for extraction, cleaning, and semantic enrichment. <a href="#usage">Section 6</a> presents usage scenarios and queries that demonstrate how the resource supports historical research. Finally, <a href="#conclusion">Section 7</a> concludes with a summary of contributions and future directions.</p>

      </div>
</section>

  <section id="relatedwork" inlist="" rel="schema:hasPart" resource="#relatedwork">
<div datatype="rdf:HTML" property="schema:description">
        <h2 property="schema:name">Related Work</h2>

        <p>A growing body of research in digital humanities and cultural heritage has increasingly adopted Semantic Web technologies to structure, enrich, and interlink historical textual corpora. Notable examples include <span property="schema:citation http://purl.org/spar/cito/cites" resource="https://dx.doi.org/10.3233/SW-223034"><a href="  https://journals.sagepub.com/doi/abs/10.3233/SW-223034 ">WarSampo</a></span> <span class="references">[<a href="#ref-1">1</a>]</span>, which models World War II data from Finland as Linked Open Data, and <a href="cites:cite enslaved, enslavedontology">Enslaved.org</a>, which applies graph-based modeling to records from the transatlantic slave trade. These projects demonstrate how knowledge graphs can be used to represent complex relationships among people, places, and events in heterogeneous historical sources.</p>

        <p>At the national level, initiatives such as the Europeana Data Model <span property="schema:citation http://purl.org/spar/cito/cites" resource="https://dx.doi.org/10.1177/03400352231202506"><a href="https://doi.org/10.1177/03400352231202506">EDM</a></span> <span class="references">[<a href="#ref-2">2</a>]</span> and the National Library of Scotland’s <a href="https://data.nls.uk/data/digitised-collections/">Data Foundry</a> exemplify large-scale digitization and metadata modeling efforts aimed at improving accessibility and reuse of cultural heritage data. Europeana promotes interoperability through linked data principles and vocabulary standardization, while the NLS provides high-quality scans and ALTO XML for thousands of 19th-century documents, including the <a href="https://data.nls.uk/data/digitised-collections/gazetteers-of-scotland/">Gazetteers of Scotland</a>.</p>

        <p>Nevertheless, these infrastructures alone are insufficient for corpora like Scottish gazetteers, which present significant challenges: noisy OCR, lack of article-level segmentation, mid-page article starts, and inconsistent editorial conventions across editions. Traditional approaches to structuring such texts—including rule-based or statistical methods—often fail under these conditions. Prior work on historical textual collections, such as newspapers or the Encyclopaedia Britannica (e.g., using the <code>defoe</code> <span property="schema:citation http://purl.org/spar/cito/cites" resource="https://dx.doi.org/10.1109/eScience51609.2021.00012"><a href="https://doi.org/10.1109/eScience51609.2021.00012">library</a></span> <span class="references">[<a href="#ref-3">3</a>]</span> has demonstrated the need for scalable, domain-adapted pipelines.</p>

        <p>Recent breakthroughs in large language models (LLMs) such as <span property="schema:citation http://purl.org/spar/cito/cites" resource="https://dx.doi.org/10.48550/arXiv.2303.08774"><a href="https://arxiv.org/abs/2303.08774">GPT-4</a></span> <span class="references">[<a href="#ref-4">4</a>]</span> open new possibilities for flexible text interpretation and segmentation. Our project leverages these models at scale with custom prompts tailored to the editorial style of each edition. This enables us to segment and extract over 50,000 structured article-level entries from ten 19th-century gazetteer volumes, while handling abbreviation styles, redirects, and evolving toponym usage.</p>

        <p>Beyond extraction, semantic modeling is critical to ensuring data reusability and interpretability. We build on and extend prior ontologies developed for cultural heritage contexts—such as the Encyclopaedia Britannica Ontology <span class="references">[<a href="#ref-5">5</a>]</span> and the National Library of Scotland Ontology <span class="references">[<a href="#ref-6">6</a>]</span>—to model bibliographic provenance and source structure. However, these earlier ontologies were not designed to represent the full diachronic and computational transformation history of digitized corpora. To address this gap, we introduced in our previous <span property="schema:citation http://purl.org/spar/cito/cites" resource="https://dx.doi.org/10.1109/E-SCIENCE62913.2024.10678663"><a href="https://doi.org/10.1109/e-Science62913.2024.10678663">work</a></span> <span class="references">[<a href="#ref-7">7</a>]</span> the <a href="https://w3id.org/hto">Heritage Textual Ontology</a> (HTO <span class="references">[<a href="#ref-8">8</a>]</span>), which provides a provenance-aware semantic framework that models not only the source structure and bibliographic metadata, but also digitization context, Name Entity Recognition (NER)-based outputs, and semantic enrichments. HTO integrates concepts from <a property="schema:citation http://purl.org/spar/cito/cites" href="https://www.w3.org/TR/prov-o/">PROV-O</a> <span class="references">[<a href="#ref-9">9</a>]</span> and <a href="https://schema.org">Schema.org</a>, but extends them with domain-specific classes and properties tailored to heritage corpora, supporting integration of various data sources from the same corpora.</p>

        <p>Finally, our work is fully integrated into the <span property="schema:citation http://purl.org/spar/cito/cites" resource="https://dx.doi.org/10.1109/E-SCIENCE62913.2024.10678663"><a href="https://doi.org/10.1109/e-Science62913.2024.10678663">Frances</a></span> <span class="references">[<a href="#ref-7">7</a>]</span> semantic platform, which supports temporal exploration and semantic search of historical data. Recent updates to Frances, include improved support for concept clustering, knowledge graph visualization, and extensible RDF modeling, making MappingChange a robust and reusable infrastructure for temporal knowledge base construction in historical research.</p>

      </div>
</section>

  <section id="resourcedescription" inlist="" rel="schema:hasPart" resource="#resourcedescription">
<div datatype="rdf:HTML" property="schema:description">
        <h2 property="schema:name">Resource Description</h2>

        <p>The MappingChange resource provides a reusable, modular knowledge base that transforms the digitized <a href="https://data.nls.uk/data/metadata-collections/gazetteers-of-scotland/">Gazetteers of Scotland</a> (1803–1901) into a structured and semantically enriched dataset for historical place-based analysis. Central to the resource are volume-specific JSON DataFrames containing over 50,000 articles—each corresponding to a place entry—extracted from OCR-aligned ALTO XML using edition-specific GPT-4 prompts. These DataFrames include article text, identified place names, and structured metadata such as edition, volume, page number, and word count. They serve as the foundation for the construction of three interlinked RDF knowledge graphs, modeled using the <a href="https://w3id.org/hto">Heritage Textual Ontology (HTO)</a>, which captures both textual provenance and semantic transformations.</p>

        <p>The first knowledge graph encodes cleaned article-level records and their bibliographic context, preserving references to their original digitized pages. The second graph introduces concept-level alignment by clustering semantically equivalent entries across editions, assigning persistent identifiers and linking them to external entities such as <a href="https://www.wikidata.org">Wikidata</a> and <a href="https://www.dbpedia.org">DBpedia</a>. The third graph adds geographic enrichment, using named entity recognition and georesolution techniques to annotate articles with location coordinates and spatial types. Together, these layers enable advanced temporal and semantic analysis of how places were described over time in the Scottish Gazetteers.</p>

        <p>All knowledge graphs are serialized in RDF/Turtle and adhere to FAIR data principles. Outputs are hosted in a public Fuseki SPARQL endpoint and are complemented by a set of Elasticsearch indices that support both traditional keyword search and vector-based semantic similarity queries. These indices cover articles, concepts, and external entity links, enabling fast and flexible retrieval across editions and enrichment layers. All components are deployed within the <a href="http://www.frances-ai.com">Frances</a> semantic platform, providing users with interactive interfaces for querying, timeline visualization, and concept exploration.</p>

        <p>The full resource—including DataFrames, RDF files, and search indices—is openly available at <a href="https://github.com/francesNLP/MappingChange">https:/​/​github.com/francesNLP/MappingChange</a>, with persistent identifiers to be issued via Zenodo. The <a href="https://w3id.org/hto">HTO ontology</a> is developed in an open repository under a CC-BY 4.0 license. To promote reuse and reproducibility, the repository includes modular scripts and comprehensive documentation. The step-by-step process by which these resources are constructed—including article extraction, prompt design, semantic clustering, and enrichment—is detailed in <a href="#resourceconstruction">Section 5</a>.</p>

      </div>
</section>

  <section id="hto" inlist="" rel="schema:hasPart" resource="#hto">
<div datatype="rdf:HTML" property="schema:description">
        <h2 property="schema:name">Heritage Textual Ontology</h2>

        <p>The <a href="https://w3id.org/hto">Heritage Textual Ontology (HTO)</a> provides the semantic backbone for <em>Mapping Change</em>, enabling structured representation of historical textual records, their provenance, and evolving place-based concepts. Since its initial release, HTO has undergone substantial refinement to support richer semantic modeling, improved interoperability, and enhanced tracking of digitization workflows and AI-assisted outputs. It is designed to model not just entities and attributes but also the editorial and computational processes by which each record is extracted, cleaned, and enriched. Unlike generic ontologies, HTO supports the representation of textual provenance, extraction prompts, editorial hierarchies, and diachronic linkage across editions. It enables us to track how descriptions of the same place evolve over time, with full transparency into their source structure and transformation process. Its design has been guided by real-world use cases in digital heritage, and it plays a central role in making the resulting knowledge graphs both expressive and reproducible.</p>

        <p>The ontology is openly developed at <a href="https://github.com/frances-ai/HeritageTextOntology">github.com/frances-ai/HeritageTextOntology</a>, and its documentation, including diagrams and examples, is available at <a href="https://w3id.org/hto">w3id.org/hto</a>.</p>

        <h3 id="key-ontological-enhancements">Key Ontological Enhancements</h3>

        <ul>
          <li>
            <p><strong>Textual Record Modeling</strong>: New classes such as <code>HTO:Article</code>, <code>HTO:PlaceRecord</code>, <code>HTO:InternalRecord</code>, and <code>HTO:TermRecord</code> differentiate between OCR-extracted fragments, cleaned entries, and semantically disambiguated concepts. The <code>HTO:Description</code> class tracks structured outputs from GPT-4, manual annotations, or post-processing tools.</p>
          </li>
          <li>
            <p><strong>Digitization Provenance</strong>: Bibliographic metadata is modeled using <code>HTO:Work</code>, <code>HTO:Volume</code>, and <code>HTO:Edition</code>, with provenance relationships defined via <a href="https://www.w3.org/TR/prov-o/">PROV-O</a> and <a href="https://schema.org">schema.org</a>. Each <code>HTO:Article</code> is linked to its digitized source via permanent NLS page URLs and includes annotations such as <code>HTO:textQuality</code> to assess OCR accuracy and reliability.</p>
          </li>
          <li>
            <p><strong>Concept Evolution and Semantic Clustering</strong>: <code>HTO:Concept</code> is used in combination with <a href="https://www.w3.org/TR/skos-reference/">SKOS</a> to group equivalent or evolving place references across multiple gazetteer editions. Concepts can represent locations, institutions, or geographical types and are dynamically inferred from embeddings and term clustering.</p>
          </li>
          <li>
            <p><strong>Geographic and Type Annotation</strong>: The ontology introduces <code>HTO:GeographicAnnotation</code> for storing lat/lon coordinates derived from external services or contextual inference. It also includes <code>HTO:LocationType</code> for classifying place categories (e.g., parish, river, estate).</p>
          </li>
          <li>
            <p><strong>Linking and External Alignment</strong>: Instances of <code>HTO:PlaceRecord</code> and <code>HTO:Concept</code> may include links to external resources using <code>HTO:externalMatch</code>, allowing interconnection with <a href="https://www.wikidata.org">Wikidata</a>, <a href="https://www.dbpedia.org">DBpedia</a>, and other knowledge bases.</p>
          </li>
          <li>
            <p><strong>Lineage and Versioning Support</strong>: Using <code>HTO:wasDerivedFrom</code>, <code>HTO:wasRecordedIn</code>, and <code>HTO:hasTextQuality</code>, the ontology supports full lineage tracking from OCR to human-reviewed RDF. This is critical for understanding transformations across stages of digitization, modeling, and enrichment.</p>
          </li>
        </ul>

        <h3 id="example-use-in-mapping-change">Example Use in Mapping Change</h3>

        <p>Each gazetteer article is instantiated as an <code>HTO:Article</code>, linked to its originating <code>HTO:Volume</code> and to one or more <code>HTO:Concept</code>s (e.g., “Aberdeen”). Concepts aggregate variations of place descriptions across editions, while RDF-level annotations record when, where, and how each article was extracted or transformed.</p>

        <p>Prompt templates and GPT outputs are represented as <code>HTO:InformationResource</code>s, allowing clear documentation of AI-assisted steps. This structured metadata facilitates reproducibility and comparative studies across digitized corpora.</p>

        <p>HTO is designed to be extensible and aligns with best practices in cultural heritage modeling, combining traditional bibliographic ontologies with novel AI-aware components.</p>

      </div>
</section>

  <section id="resourceconstruction" inlist="" rel="schema:hasPart" resource="#resourceconstruction">
<div datatype="rdf:HTML" property="schema:description">
        <h2 property="schema:name">Construction and Content</h2>

        <p>The resource was built using a modular pipeline comprising:</p>

        <h3 id="extraction">Extraction</h3>

        <ul>
          <li>Volume-specific scripts (e.g., <a href="https://github.com/francesNLP/MappingChange/blob/main/src/extract_gaz_1803.py">extract_gaz_1803.py</a>) segment OCR text using GPT-4 with prompts adapted to differing article structures.</li>
          <li>Prompts handle varying formats, including mid-page entries, redirects, and irregular headers.</li>
        </ul>

        <h4 id="volume-specific-prompt-engineering">Volume-Specific Prompt Engineering</h4>

        <p>Because each Gazetteer edition between 1803 and 1901 features highly distinct layout conventions (e.g., capitalization, abbreviations, header formatting, article delimiters), we could not apply a single uniform prompt across all volumes. Instead, we designed <strong>custom GPT-4 prompts</strong> for each edition to ensure accurate article segmentation and place name extraction.</p>

        <p>The table below summarizes the key differences and our adaptation strategies:</p>

        <table>
          <thead>
            <tr>
              <th>Gazetteer Volume</th>
              <th>Prompt Focus</th>
              <th>Format Characteristics</th>
              <th>Prompt Adaptation Strategy</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>1803</td>
              <td>Entry detection in irregular formatting</td>
              <td>Short entries, inconsistent punctuation</td>
              <td>Prompt includes examples with minimal structure; stresses sentence-level cues for boundaries</td>
            </tr>
            <tr>
              <td>1806</td>
              <td>Parsing longer headers</td>
              <td>Descriptive headers like “Parish of…”</td>
              <td>Prompt highlights multi-word headers and requests exact header extraction</td>
            </tr>
            <tr>
              <td>1825</td>
              <td>Delimiting fused articles</td>
              <td>Minimal line breaks between articles</td>
              <td>Prompt stresses lexical patterns (e.g., place types, initial caps) to find boundaries</td>
            </tr>
            <tr>
              <td>1838</td>
              <td>Handling abbreviations and symbols</td>
              <td>Use of brackets, abbreviations for counties</td>
              <td>Prompt includes example abbreviations and instructions to include them in headers</td>
            </tr>
            <tr>
              <td>1842</td>
              <td>Identifying hierarchical entries</td>
              <td>Entries with sub-places or parenthesized detail</td>
              <td>Prompt uses hierarchical examples and specifies nested JSON structure</td>
            </tr>
            <tr>
              <td>1846</td>
              <td>Normalizing inconsistent capitalization</td>
              <td>Random capital words mid-paragraph</td>
              <td>Prompt emphasizes ignoring internal caps unless followed by specific patterns</td>
            </tr>
            <tr>
              <td>1868</td>
              <td>Filtering out printed annotations</td>
              <td>Use of special characters, side notes</td>
              <td>Prompt includes rule to ignore marginal notes or typesetting artifacts</td>
            </tr>
            <tr>
              <td>1884 &amp; 1901</td>
              <td>Unified structured prompt</td>
              <td>Consistent bold headers, clear formatting</td>
              <td>A single prompt applied to both; relies on standard visual patterns and separators</td>
            </tr>
          </tbody>
        </table>

        <p>Each prompt is represented as an instance of <code>HTO:InformationResource</code>, enabling traceable documentation of prompt design and LLM usage in our pipeline.</p>

        <h3 id="cleaning--deduplication">Cleaning &amp; Deduplication</h3>

        <ul>
          <li>Cleaned JSON outputs are merged.</li>
          <li>Fuzzy matching, prefix-trees, and substring containment detect duplicates across years and within volumes.</li>
        </ul>

        <h3 id="dataframe-generation">DataFrame Generation</h3>

        <ul>
          <li>Unified metadata from OCR, XML, and GPT outputs are exported to structured JSON-based DataFrames.</li>
        </ul>

        <h3 id="knowledge-graph-generation">Knowledge Graph Generation</h3>

        <ul>
          <li>RDF triples are created using the improved HTO ontology.</li>
          <li>Entities include Articles, Volumes, Concepts, and digitization provenance.</li>
        </ul>

        <h3 id="entity-linking">Entity Linking</h3>

        <ul>
          <li>Gazetteer terms are matched to DBpedia and Wikidata using label and description matching.</li>
          <li>Articles with similar embeddings are grouped into concepts using <code>all-mpnet-base-v2</code>.</li>
        </ul>

        <h3 id="enrichment">Enrichment</h3>

        <ul>
          <li>Concepts are assigned summaries, sentiment values, and external links.</li>
          <li>Article timelines visualize the evolution of place concepts across editions.</li>
        </ul>

        <h3 id="search-indices">Search Indices</h3>

        <ul>
          <li>Elasticsearch indices are built for articles, Wikidata, and DBpedia entities.</li>
          <li>Vector search enables semantically similar article discovery.</li>
        </ul>

        <h3 id="geoparsing">Geoparsing</h3>

        <ul>
          <li>For enriched geospatial analysis, <code>geoparse.py</code> tags locations using SpaCy NER and Gazetteer context.</li>
        </ul>

        <p>All scripts are in <a href="https://github.com/francesNLP/MappingChange/tree/main/src">MappingChange/src/</a>, and their outputs are versioned and archived.</p>

      </div>
</section>

  <section id="usage" inlist="" rel="schema:hasPart" resource="#usage">
<div datatype="rdf:HTML" property="schema:description">
        <h2 property="schema:name">Usage</h2>

        <p>Mapping Change can be explored in three main ways:</p>

        <h3 id="data-access">Data Access</h3>
        <ul>
          <li>All cleaned DataFrames and RDF graphs are in the GitHub repository: <a href="https://github.com/francesNLP/MappingChange">francesNLP/MappingChange</a></li>
          <li>Scripts for reproducing those dataframes, KGs and ES are in the GitHub repository: <a href="https://github.com/francesNLP/MappingChange">francesNLP/MappingChange</a></li>
          <li><a href="https://zenodo.org">Zenodo DOI</a> (to be added)</li>
        </ul>

        <h3 id="sparql-querying">SPARQL Querying</h3>
        <ul>
          <li>A Fuseki SPARQL server supports knowledge graph exploration.</li>
          <li>Sample queries for retrieving places, concepts, and links are included.</li>
        </ul>

        <h3 id="frances-platform">Frances Platform</h3>
        <ul>
          <li>Users can search and explore articles via full-text or semantic search.</li>
          <li>Concepts are visualized through timelines and embeddings.</li>
        </ul>

        <h3 id="notebooks">Notebooks</h3>
        <p>Google Colab notebooks are provided for each gazetteer to enable direct exploration and analysis.</p>

      </div>
</section>

  <section id="conclussion" inlist="" rel="schema:hasPart" resource="#conclussion">
<div datatype="rdf:HTML" property="schema:description">
        <h2 property="schema:name">Conclusion</h2>

        <p><em>Mapping Change</em> creates a temporal, semantic infrastructure for exploring Scottish place descriptions from 1803–1901. Combining LLM-based extraction, improved ontology design, and semantic search, we deliver a reusable, interoperable dataset for historical research.</p>

        <p>The improved HTO ontology enables robust modeling of textual provenance, record quality, and evolving concepts. The Frances platform empowers researchers to query and visualize this data across time and space.</p>

        <p>Future work includes integrating cartographic metadata, and link it to the 100 years of the Encyclopaedia Britannica.</p>

      </div>
</section>

  <section id="acknowledgements" inlist="" rel="schema:hasPart" resource="#acknowledgements">
<div datatype="rdf:HTML" property="schema:description">
        <h2 property="schema:name">Acknowledgements</h2>

        <p>This work was supported by the Royal Society of Edinburgh (RSE Small Research Grant).</p>

      </div>
</section>


</main>


<footer><section>
<h2 id="references">References</h2>
<dl class="references">
  <dt id="ref-1">[1]</dt>
  <dd resource="https://dx.doi.org/10.3233/SW-223034" typeof="schema:Article">Hyvönen, E.: Digital humanities on the Semantic Web: Sampo model and portal series. Semantic Web. 14, 729–744 (2023). doi:10.3233/SW-223034</dd>
  <dt id="ref-2">[2]</dt>
  <dd resource="https://dx.doi.org/10.1177/03400352231202506" typeof="schema:Article">Silva, A.L., Terra, A.L.: Cultural heritage on the Semantic Web: The Europeana Data Model. IFLA Journal. 0, 03400352231202506 (0AD). doi:10.1177/03400352231202506</dd>
  <dt id="ref-3">[3]</dt>
  <dd resource="https://dx.doi.org/10.1109/eScience51609.2021.00012" typeof="schema:Article">Filgueira, R., Grover, C., others: Extending defoe for the efficient analysis of historical texts at scale. In: 2021 IEEE 17th International Conference on eScience (eScience). pp. 21–29 (2021). doi:10.1109/eScience51609.2021.00012</dd>
  <dt id="ref-4">[4]</dt>
  <dd resource="https://dx.doi.org/10.48550/arXiv.2303.08774" typeof="schema:CreativeWork">OpenAI: GPT-4 Technical Report. <a href="https://arxiv.org/abs/2303.08774">https:/​/​arxiv.org/abs/2303.08774</a> (2023). doi:10.48550/arXiv.2303.08774</dd>
  <dt id="ref-5">[5]</dt>
  <dd resource="#ebontology" typeof="schema:CreativeWork">Filgueira, R.: Encyclopaedia Britannica Ontology. <a href="https://w3id.org/eb">https:/​/​w3id.org/eb</a> (2023).</dd>
  <dt id="ref-6">[6]</dt>
  <dd resource="#nlsontology" typeof="schema:CreativeWork">Filgueira, R.: National Library of Scotland Ontology. <a href="https://w3id.org/nls">https:/​/​w3id.org/nls</a> (2023).</dd>
  <dt id="ref-7">[7]</dt>
  <dd resource="https://dx.doi.org/10.1109/E-SCIENCE62913.2024.10678663" typeof="schema:Article">Yu, L., Charlton, A., Terras, M., Filgueira, R.: Advancing frances: New Heritage Textual Ontology, Enhanced Knowledge Graphs, and Refined Search Capabilities. In: 20th IEEE International Conference on e-Science, e-Science 2024, Osaka, Japan, September 16-20, 2024. pp. 1–10. IEEE (2024). doi:10.1109/E-SCIENCE62913.2024.10678663</dd>
  <dt id="ref-8">[8]</dt>
  <dd resource="#hto" typeof="schema:CreativeWork">Yu, L., Filgueira, R.: The Heritage Textual Ontology (HTO). <a href="https://github.com/frances-ai/HeritageTextOntology">https:/​/​github.com/frances-ai/HeritageTextOntology</a> (2024).</dd>
  <dt id="ref-9">[9]</dt>
  <dd resource="https://www.w3.org/TR/prov-o/" typeof="schema:CreativeWork">Groth, P., others: PROV-Overview. W3C, <a href="https://www.w3.org/TR/prov-o/">https:/​/​www.w3.org/TR/prov-o/</a> (2013).</dd>
</dl>
</section>
</footer>
</div>



</body>
</html>
